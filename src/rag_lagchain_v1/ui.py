from __future__ import annotations

import streamlit as st
from pathlib import Path

from .config import get_config
from .ingestion import load_and_split
from .vectorstore import index_documents, similarity_search
from .agent import build_graph, RAGState
from .admin import admin_page


def app():
    st.set_page_config(page_title="RAG LangGraph App", page_icon="ü§ñ")
    
    # Sidebar navigation
    st.sidebar.title("ü§ñ RAG Navigator")
    page = st.sidebar.radio(
        "Ch·ªçn trang:",
        ["üìù Q&A", "üîß Qu·∫£n l√Ω"],
        index=0
    )
    
    if page == "üîß Qu·∫£n l√Ω":
        admin_page()
        return
    
    # Main Q&A page
    st.title("RAG Q&A v·ªõi LangChain + LangGraph + Qdrant")

    cfg = get_config()

    with st.expander("C·∫•u h√¨nh"):
        st.write(
            {
                "Qdrant": cfg.qdrant_url,
                "Collection": cfg.qdrant_collection,
                "Embedding": cfg.embedding_model,
                "LLM": cfg.openai_model,
            }
        )

    st.subheader("T·∫£i l√™n t√†i li·ªáu")
    uploaded_files = st.file_uploader(
        "Ch·ªçn file (.pdf, .docx, .txt, .md)",
        accept_multiple_files=True,
        type=["pdf", "docx", "txt", "md"],
    )

    if uploaded_files and st.button("N·∫°p & L·∫≠p ch·ªâ m·ª•c"):
        total = 0
        with st.spinner("ƒêang x·ª≠ l√Ω..."):
            items = []
            for f in uploaded_files:
                chunks = load_and_split(
                    f.name,
                    f.read(),
                    chunk_size=cfg.chunk_size,
                    chunk_overlap=cfg.chunk_overlap,
                )
                items.extend(chunks)
            total = index_documents(items)
        st.success(f"ƒê√£ l·∫≠p ch·ªâ m·ª•c {total} chunks")

    st.subheader("H·ªèi ƒë√°p")
    question = st.text_input("C√¢u h·ªèi c·ªßa b·∫°n")
    if st.button("H·ªèi") and question:
        graph = build_graph()
        state = RAGState(question=question)
        with st.spinner("ƒêang t·∫°o c√¢u tr·∫£ l·ªùi..."):
            result = graph.invoke(state)
        
        st.markdown("**C√¢u tr·∫£ l·ªùi:**")
        st.write(result["answer"])
        
        # Get context documents to check for multimedia content
        docs = similarity_search(question, k=5)
        
        # Show tables if question mentions relevant keywords
        if any(keyword in question.lower() for keyword in ["b·∫£ng", "table", "t√°c ƒë·ªông", "bbkh", "khu v·ª±c", "lo·∫°i"]):
            tables_found = []
            for doc in docs:
                if "tables" in doc.metadata:
                    tables_found.extend(doc.metadata["tables"])
            
            if tables_found:
                st.markdown("**B·∫£ng li√™n quan:**")
                for i, table_dict in enumerate(tables_found[:3]):  # Limit to 3 tables
                    st.markdown(f"**B·∫£ng {i+1} (Trang {table_dict['page']}):**")
                    st.dataframe(table_dict['data'], use_container_width=True)
        
        # Show images if question mentions relevant keywords
        if any(keyword in question.lower() for keyword in ["h√¨nh", "·∫£nh", "th·ª±c t·∫ø", "v√πng", "·∫£nh h∆∞·ªüng"]):
            images_found = []
            for doc in docs:
                if "images" in doc.metadata:
                    images_found.extend(doc.metadata["images"])
            
            if images_found:
                st.markdown("**H√¨nh ·∫£nh li√™n quan:**")
                cols = st.columns(min(len(images_found), 3))
                for i, img_path in enumerate(images_found[:6]):  # Limit to 6 images
                    if Path(img_path).exists():
                        with cols[i % 3]:
                            st.image(img_path, caption=Path(img_path).name, width=200)
                    else:
                        st.warning(f"Kh√¥ng t√¨m th·∫•y file h√¨nh ·∫£nh: {img_path}")


if __name__ == "__main__":
    app()
